{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/anaconda3/envs/spacepost/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import h5py\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from cv2 import imwrite\n",
    "from keras import Input, Model\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.layers import Convolution2D, LeakyReLU, BatchNormalization, UpSampling2D, Dropout, Activation, Flatten, \\\n",
    "    Dense, Lambda, Reshape, concatenate\n",
    "from keras.optimizers import Adam\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps done so far\n",
    "\n",
    "- Pictures from sprite kit cropped (113 in total)\n",
    "- Picures resized to 50 X50 pixels\n",
    "\n",
    "## Steps needed\n",
    "- Need real/ 3d pictures for mapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def U_net_Generator():\n",
    "    \"\"\"\n",
    "    This U_net style CNN will  be used  as the generator for generating images\n",
    "\n",
    "    https://arxiv.org/pdf/1505.04597.pdf  For the method behind the madness\n",
    "    \n",
    "    Fully convoluted with no softmax,,,ect at the end as\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    leaky_relu_alpha = 0.3 # needed for the down sampling\n",
    "    \n",
    "    \n",
    "    upsampling_size = 2\n",
    "    dropout = 0.25       # drop out of 1/4th of the data to keep the network learning will adjust based on tests later on\n",
    "    output_channels = 1 # Set to one as each loop in the training will have a single output\n",
    "                        # channel for the discrimator to test on\n",
    "    input_shape = (50, 50, 1) # image dimensions for this test set will be set to 50px by 50px\n",
    "    input_layer = Input(shape=input_shape) # \n",
    "    kernel_size = 4\n",
    "    stride_size = 2\n",
    "\n",
    "   \n",
    "\n",
    "\n",
    "    # Encoder Network\n",
    "    \n",
    "    # This network is used to down sample the input images\n",
    "    # Padding is kept at the same since it is fully convoluted\n",
    "\n",
    "    # 1st Convolutional block in the encoder network\n",
    "    encoder1 = Convolution2D(filters=64, kernel_size=kernel_size, padding='same',strides=stride_size)(input_layer)\n",
    "    # no need for batch normalization here! I'ts the first layer\n",
    "    encoder1 = LeakyReLU(alpha=leaky_relu_alpha)(encoder1)\n",
    "\n",
    "    # 2nd Convolutional block in the encoder network\n",
    "    encoder2 = Convolution2D(filters=128, kernel_size=kernel_size, padding='same',strides=stride_size)(encoder1)\n",
    "    encoder2 = BatchNormalization()(encoder2)\n",
    "\n",
    "    encoder2 = LeakyReLU(alpha=leaky_relu_alpha)(encoder2)\n",
    "\n",
    "    # 3rd Convolutional block in the encoder network\n",
    "    encoder3 = Convolution2D(filters=256, kernel_size=kernel_size, padding='same',strides=stride_size)(encoder2)\n",
    "    encoder3 = BatchNormalization()(encoder3)\n",
    "    encoder3 = LeakyReLU(alpha=leaky_relu_alpha)(encoder3)\n",
    "\n",
    "    # 4th Convolutional block in the encoder network\n",
    "    encoder4 = Convolution2D(filters=512, kernel_size=kernel_size, padding='same',strides=stride_size)(encoder3)\n",
    "    encoder4 = BatchNormalization()(encoder4)\n",
    "    encoder4 = LeakyReLU(alpha=leaky_relu_alpha)(encoder4)\n",
    "\n",
    "    # 5th Convolutional block in the encoder network\n",
    "    encoder5 = Convolution2D(filters=512, kernel_size=kernel_size, padding='same',strides=stride_size)(encoder4)\n",
    "    encoder5 = BatchNormalization()(encoder5)\n",
    "    encoder5 = LeakyReLU(alpha=leaky_relu_alpha)(encoder5)\n",
    "\n",
    "    # 6th Convolutional block in the encoder network\n",
    "    encoder6 = Convolution2D(filters=512, kernel_size=kernel_size, padding='same',strides=stride_size)(encoder5)\n",
    "    encoder6 = BatchNormalization()(encoder6)\n",
    "    encoder6 = LeakyReLU(alpha=leaky_relu_alpha)(encoder6)\n",
    "\n",
    "    # 7th Convolutional block in the encoder network\n",
    "    encoder7 = Convolution2D(filters=512, kernel_size=kernel_size, padding='same',strides=stride_size)(encoder6)\n",
    "    encoder7 = BatchNormalization()(encoder7)\n",
    "    encoder7 = LeakyReLU(alpha=leaky_relu_alpha)(encoder7)\n",
    "\n",
    "    # 8th Convolutional block in the encoder network\n",
    "    encoder8 = Convolution2D(filters=512, kernel_size=kernel_size, padding='same',strides=stride_size)(encoder7)\n",
    "    encoder8 = BatchNormalization()(encoder8)\n",
    "    encoder8 = LeakyReLU(alpha=leaky_relu_alpha)(encoder8)\n",
    "\n",
    "    # Decoder Network\n",
    "\n",
    "    # 1st Upsampling Convolutional Block in the decoder network\n",
    "    decoder1 = UpSampling2D(size=upsampling_size)(encoder8)\n",
    "    decoder1 = Convolution2D(filters=512, kernel_size=kernel_size, padding='same')(decoder1)\n",
    "    decoder1 = BatchNormalization()(decoder1)\n",
    "    decoder1 = Dropout(dropout)(decoder1)\n",
    "    decoder1 = concatenate([decoder1, encoder7], axis=3)\n",
    "    decoder1 = Activation('relu')(decoder1)\n",
    "\n",
    "    # 2nd Upsampling Convolutional block in the decoder network\n",
    "    decoder2 = UpSampling2D(size=upsampling_size)(decoder1)\n",
    "    decoder2 = Convolution2D(filters=1024, kernel_size=kernel_size, padding='same')(decoder2)\n",
    "    decoder2 = BatchNormalization()(decoder2)\n",
    "    decoder2 = Dropout(dropout)(decoder2)\n",
    "    decoder2 = concatenate([decoder2, encoder6])\n",
    "    decoder2 = Activation('relu')(decoder2)\n",
    "\n",
    "    # 3rd Upsampling Convolutional block in the decoder network\n",
    "    decoder3 = UpSampling2D(size=upsampling_size)(decoder2)\n",
    "    decoder3 = Convolution2D(filters=1024, kernel_size=kernel_size, padding='same')(decoder3)\n",
    "    decoder3 = BatchNormalization()(decoder3)\n",
    "    decoder3 = Dropout(dropout)(decoder3)\n",
    "    decoder3 = concatenate([decoder3, encoder5])\n",
    "    decoder3 = Activation('relu')(decoder3)\n",
    "\n",
    "    # 4th Upsampling Convolutional block in the decoder network\n",
    "    decoder4 = UpSampling2D(size=upsampling_size)(decoder3)\n",
    "    decoder4 = Convolution2D(filters=1024, kernel_size=kernel_size, padding='same')(decoder4)\n",
    "    decoder4 = BatchNormalization()(decoder4)\n",
    "    decoder4 = concatenate([decoder4, encoder4])\n",
    "    decoder4 = Activation('relu')(decoder4)\n",
    "\n",
    "    # 5th Upsampling Convolutional block in the decoder network\n",
    "    decoder5 = UpSampling2D(size=upsampling_size)(decoder4)\n",
    "    decoder5 = Convolution2D(filters=1024, kernel_size=kernel_size, padding='same')(decoder5)\n",
    "    decoder5 = BatchNormalization()(decoder5)\n",
    "    decoder5 = concatenate([decoder5, encoder3])\n",
    "    decoder5 = Activation('relu')(decoder5)\n",
    "\n",
    "    # 6th Upsampling Convolutional block in the decoder network\n",
    "    decoder6 = UpSampling2D(size=upsampling_size)(decoder5)\n",
    "    decoder6 = Convolution2D(filters=512, kernel_size=kernel_size, padding='same')(decoder6)\n",
    "    decoder6 = BatchNormalization()(decoder6)\n",
    "    decoder6 = concatenate([decoder6, encoder2])\n",
    "    decoder6 = Activation('relu')(decoder6)\n",
    "\n",
    "    # 7th Upsampling Convolutional block in the decoder network\n",
    "    decoder7 = UpSampling2D(size=upsampling_size)(decoder6)\n",
    "    decoder7 = Convolution2D(filters=256, kernel_size=kernel_size, padding='same')(decoder7)\n",
    "    decoder7 = BatchNormalization()(decoder7)\n",
    "    decoder7 = concatenate([decoder7, encoder1])\n",
    "    decoder7 = Activation('relu')(decoder7)\n",
    "\n",
    "    # Last Convolutional layer\n",
    "    decoder8 = UpSampling2D(size=upsampling_size)(decoder7)\n",
    "    decoder8 = Convolution2D(filters=output_channels, kernel_size=kernel_size, padding='same')(decoder8)\n",
    "    decoder8 = Activation('tanh')(decoder8)\n",
    "\n",
    "    generative_model = Model(inputs=[input_layer], outputs=[decoder8])\n",
    "    return generative_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# U_net_Generator()\n",
    "##testeed and only fails due to thre being no inputs just yet"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
