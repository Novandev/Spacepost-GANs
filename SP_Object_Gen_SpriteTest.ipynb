{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import h5py\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from cv2 import imwrite\n",
    "from keras import Input, Model\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.layers import Convolution2D, LeakyReLU, BatchNormalization, UpSampling2D, Dropout, Activation, Flatten, \\\n",
    "    Dense, Lambda, Reshape, concatenate\n",
    "from keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps done so far\n",
    "\n",
    "- Pictures from sprite kit cropped (113 in total)\n",
    "- Picures resized to 50 X50 pixels\n",
    "\n",
    "## Steps needed\n",
    "- Need real/ 3d pictures for mapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def P2P_U_net_Generator():\n",
    "    \"\"\"\n",
    "    This U_net style CNN will  be used  as the generator for generating images\n",
    "\n",
    "    https://arxiv.org/pdf/1505.04597.pdf  For the method behind the madness\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    leaky_relu_alpha = 0.3 # needed for the down sampling\n",
    "    \n",
    "    \n",
    "    upsampling_size = 2\n",
    "    dropout = 0.25       # drop out of 1/4th of the data to keep the network learning will adjust based on tests later on\n",
    "    output_channels = 1 # Set to one as each loop in the training will have a single output\n",
    "                        # channel for the discrimator to test on\n",
    "    input_shape = (50, 50, 1) # image dimensions for this test set will be set to 50px by 50px\n",
    "    input_layer = Input(shape=input_shape) # \n",
    "    kernel_size = 4\n",
    "    stride_size = 2\n",
    "\n",
    "   \n",
    "\n",
    "\n",
    "    # Encoder Network\n",
    "    \n",
    "    # This network is used to down sample the input images\n",
    "    # Padding is kept at the same since it is fully convoluted\n",
    "\n",
    "    # 1st Convolutional block in the encoder network\n",
    "    encoder1 = Convolution2D(filters=64, kernel_size=kernel_size, padding='same',strides=stride_size)(input_layer)\n",
    "    # no need for batch normalization here! I'ts the first layer\n",
    "    encoder1 = LeakyReLU(alpha=leaky_relu_alpha)(encoder1)\n",
    "\n",
    "    # 2nd Convolutional block in the encoder network\n",
    "    encoder2 = Convolution2D(filters=128, kernel_size=kernel_size, padding='same',strides=stride_size)(encoder1)\n",
    "    encoder2 = BatchNormalization()(encoder2)\n",
    "\n",
    "    encoder2 = LeakyReLU(alpha=leaky_relu_alpha)(encoder2)\n",
    "\n",
    "    # 3rd Convolutional block in the encoder network\n",
    "    encoder3 = Convolution2D(filters=256, kernel_size=kernel_size, padding='same',strides=stride_size)(encoder2)\n",
    "    encoder3 = BatchNormalization()(encoder3)\n",
    "    encoder3 = LeakyReLU(alpha=leaky_relu_alpha)(encoder3)\n",
    "\n",
    "    # 4th Convolutional block in the encoder network\n",
    "    encoder4 = Convolution2D(filters=512, kernel_size=kernel_size, padding='same',strides=stride_size)(encoder3)\n",
    "    encoder4 = BatchNormalization()(encoder4)\n",
    "    encoder4 = LeakyReLU(alpha=leaky_relu_alpha)(encoder4)\n",
    "\n",
    "    # 5th Convolutional block in the encoder network\n",
    "    encoder5 = Convolution2D(filters=512, kernel_size=kernel_size, padding='same',strides=stride_size)(encoder4)\n",
    "    encoder5 = BatchNormalization()(encoder5)\n",
    "    encoder5 = LeakyReLU(alpha=leaky_relu_alpha)(encoder5)\n",
    "\n",
    "    # 6th Convolutional block in the encoder network\n",
    "    encoder6 = Convolution2D(filters=512, kernel_size=kernel_size, padding='same',strides=stride_size)(encoder5)\n",
    "    encoder6 = BatchNormalization()(encoder6)\n",
    "    encoder6 = LeakyReLU(alpha=leaky_relu_alpha)(encoder6)\n",
    "\n",
    "    # 7th Convolutional block in the encoder network\n",
    "    encoder7 = Convolution2D(filters=512, kernel_size=kernel_size, padding='same',strides=stride_size)(encoder6)\n",
    "    encoder7 = BatchNormalization()(encoder7)\n",
    "    encoder7 = LeakyReLU(alpha=leaky_relu_alpha)(encoder7)\n",
    "\n",
    "    # 8th Convolutional block in the encoder network\n",
    "    encoder8 = Convolution2D(filters=512, kernel_size=kernel_size, padding='same',strides=stride_size)(encoder7)\n",
    "    encoder8 = BatchNormalization()(encoder8)\n",
    "    encoder8 = LeakyReLU(alpha=leaky_relu_alpha)(encoder8)\n",
    "\n",
    "    # Decoder Network\n",
    "\n",
    "    # 1st Upsampling Convolutional Block in the decoder network\n",
    "    decoder1 = UpSampling2D(size=upsampling_size)(encoder8)\n",
    "    decoder1 = Convolution2D(filters=512, kernel_size=kernel_size, padding='same')(decoder1)\n",
    "    decoder1 = BatchNormalization()(decoder1)\n",
    "    decoder1 = Dropout(dropout)(decoder1)\n",
    "    decoder1 = concatenate([decoder1, encoder7], axis=3)\n",
    "    decoder1 = Activation('relu')(decoder1)\n",
    "\n",
    "    # 2nd Upsampling Convolutional block in the decoder network\n",
    "    decoder2 = UpSampling2D(size=upsampling_size)(decoder1)\n",
    "    decoder2 = Convolution2D(filters=1024, kernel_size=kernel_size, padding='same')(decoder2)\n",
    "    decoder2 = BatchNormalization()(decoder2)\n",
    "    decoder2 = Dropout(dropout)(decoder2)\n",
    "    decoder2 = concatenate([decoder2, encoder6])\n",
    "    decoder2 = Activation('relu')(decoder2)\n",
    "\n",
    "    # 3rd Upsampling Convolutional block in the decoder network\n",
    "    decoder3 = UpSampling2D(size=upsampling_size)(decoder2)\n",
    "    decoder3 = Convolution2D(filters=1024, kernel_size=kernel_size, padding='same')(decoder3)\n",
    "    decoder3 = BatchNormalization()(decoder3)\n",
    "    decoder3 = Dropout(dropout)(decoder3)\n",
    "    decoder3 = concatenate([decoder3, encoder5])\n",
    "    decoder3 = Activation('relu')(decoder3)\n",
    "\n",
    "    # 4th Upsampling Convolutional block in the decoder network\n",
    "    decoder4 = UpSampling2D(size=upsampling_size)(decoder3)\n",
    "    decoder4 = Convolution2D(filters=1024, kernel_size=kernel_size, padding='same')(decoder4)\n",
    "    decoder4 = BatchNormalization()(decoder4)\n",
    "    decoder4 = concatenate([decoder4, encoder4])\n",
    "    decoder4 = Activation('relu')(decoder4)\n",
    "\n",
    "    # 5th Upsampling Convolutional block in the decoder network\n",
    "    decoder5 = UpSampling2D(size=upsampling_size)(decoder4)\n",
    "    decoder5 = Convolution2D(filters=1024, kernel_size=kernel_size, padding='same')(decoder5)\n",
    "    decoder5 = BatchNormalization()(decoder5)\n",
    "    decoder5 = concatenate([decoder5, encoder3])\n",
    "    decoder5 = Activation('relu')(decoder5)\n",
    "\n",
    "    # 6th Upsampling Convolutional block in the decoder network\n",
    "    decoder6 = UpSampling2D(size=upsampling_size)(decoder5)\n",
    "    decoder6 = Convolution2D(filters=512, kernel_size=kernel_size, padding='same')(decoder6)\n",
    "    decoder6 = BatchNormalization()(decoder6)\n",
    "    decoder6 = concatenate([decoder6, encoder2])\n",
    "    decoder6 = Activation('relu')(decoder6)\n",
    "\n",
    "    # 7th Upsampling Convolutional block in the decoder network\n",
    "    decoder7 = UpSampling2D(size=upsampling_size)(decoder6)\n",
    "    decoder7 = Convolution2D(filters=256, kernel_size=kernel_size, padding='same')(decoder7)\n",
    "    decoder7 = BatchNormalization()(decoder7)\n",
    "    decoder7 = concatenate([decoder7, encoder1])\n",
    "    decoder7 = Activation('relu')(decoder7)\n",
    "\n",
    "    # Last Convolutional layer\n",
    "    decoder8 = UpSampling2D(size=upsampling_size)(decoder7)\n",
    "    decoder8 = Convolution2D(filters=output_channels, kernel_size=kernel_size, padding='same')(decoder8)\n",
    "    decoder8 = Activation('tanh')(decoder8)\n",
    "\n",
    "    generative_model = Model(inputs=[input_layer], outputs=[decoder8])\n",
    "    return generative_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "stride_size_descrim = 2\n",
    "kernel_size = 4\n",
    "leaky_relu_alpha_descrim = 0.3\n",
    "num_filters_start = 64  # Number of filters to start with\n",
    "num_kernels = 100\n",
    "kernel_dim = 5\n",
    "discrim_output_shape = (50, 50, 1) # Image shape will follow the same pixels at the U_net generator above\n",
    "discrim_input_shape = (50, 50, 1) # Image output shape should have the same pixel deminsion as the genrator network\n",
    "\n",
    "# number of patches for discriminator\n",
    "numb_of_patches = int((discrim_output_shape[0] / discrim_input_shape[0]) * (discrim_output_shape[1] / discrim_input_shape[1]))\n",
    "\n",
    "\n",
    "def p2p_discriminator():\n",
    "    \"\"\"\n",
    "    The Architecture of the discrminator is based off of that of the Patch GAN as described by the following paper:\n",
    "    \n",
    "    https://arxiv.org/abs/1611.07004\n",
    "    \n",
    "    \"\"\"\n",
    "    # Define the input layer for the network\n",
    "    input_layer = Input(shape=discrim_input_shape)\n",
    "    \n",
    "    descriminator = Convolution2D(filters=64, kernel_size=kernel_size, padding='same', strides=stride_size)(input_layer)\n",
    "    descriminator = LeakyReLU(alpha=leaky_relu_alpha_descrim)(descriminator)\n",
    "    \n",
    "    # Calculate the number of convolutional layers in this run\n",
    "    total_convolutional_layers = int(np.floor(np.log(discrim_output_shape[1]) / np.log(2)))\n",
    "    \n",
    "    filters_list = [num_filters_start * min(total_convolutional_layers, (2 ** i)) for i in range(total_convolutional_layers)]\n",
    "    \n",
    "    # Using a list slice to get the next 7 layers in an orderly fashion\n",
    "    for filters in filters_list[1:]:\n",
    "        descriminator = Convolution2D(filters=filters, kernel_size=kernel_size, padding=padding, strides=stride_size_descrim)(descriminator)\n",
    "        descriminator = BatchNormalization()(descriminator)\n",
    "        descriminator = LeakyReLU(alpha=leaky_relu_alpha_descrim)(descriminator)\n",
    "        \n",
    "        \n",
    "    # Adding a flatten layer to the network to turn the next step into a 1D tensor for the softmax coming up\n",
    "    flattener = Flatten()(descriminator)\n",
    "    \n",
    "    # Softmax Layer\n",
    "    dense_layer = Dense(units=2, activation='softmax')(flattener)\n",
    "    \n",
    "    # Creates a keras model for the patch gans discriminator network\n",
    "    model_discriminator = Model(inputs=[input_layer], outputs=[dense_layer, flattener])\n",
    "    \n",
    "    # Create a list of input layers equal to number of patches\n",
    "    input_layers_list = [Input(shape=discrim_input_shape) for _ in range(numb_of_patches)]\n",
    "    \n",
    "    # Pass the patches to the Model discriminator and get the probability distribution for the model\n",
    "    output1 = [model_discriminator(patch)[0] for patch in input_layers_list]\n",
    "    output2 = [model_discriminator(patch)[1] for patch in input_layers_list]\n",
    "    \n",
    "    # In case of multiple patches, concatinate to calculate loss\n",
    "    if len(output1) > 1:\n",
    "        output1 = concatenate(output1)\n",
    "    else:\n",
    "        output1 = output1[0]\n",
    "\n",
    "    # if multiple patches exist, merge output2 as well\n",
    "    if len(output2) > 1:\n",
    "        output2 = concatenate(output2)\n",
    "    else:\n",
    "        output2 = output2[0]\n",
    "        \n",
    "    # Add a dense layer\n",
    "    dense_layer2 = Dense(num_kernels * kernel_dim, use_bias=False, activation=None)\n",
    "\n",
    "    # Add a lambda layer taken from a textbook that works fine with this network untill the return\n",
    "    custom_loss_layer = Lambda(lambda x: K.sum(\n",
    "            K.exp(-K.sum(K.abs(K.expand_dims(x, 3) - K.expand_dims(K.permute_dimensions(x, pattern=(1, 2, 0)), 0)), 2)), 2))\n",
    "\n",
    "    # Pass the output2 tensor through dense_layer2\n",
    "    output2 = dense_layer2(output2)\n",
    "\n",
    "    # Reshape the output2 tensor to fit the kernel dimnetions\n",
    "    output2 = Reshape((num_kernels, kernel_dim))(output2)\n",
    "\n",
    "    # Pass the output2 tensor through the custom_loss_layer\n",
    "    output2 = custom_loss_layer(output2)\n",
    "\n",
    "    # Finally concatenate output1 and output2\n",
    "    output1 = concatenate([output1, output2])\n",
    "    \n",
    "    # pass ot to a sfotmax function to get probablities\n",
    "    final_output = Dense(2, activation=\"softmax\")(output1)\n",
    "\n",
    "    # Create a discriminator model\n",
    "    discriminator = Model(inputs=input_layers_list, outputs=[final_output])\n",
    "    \n",
    "    # Return discriminator\n",
    "    return discriminator\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pix2pix_network(generator, discriminator):\n",
    "\n",
    "    patch_shape = (50, 50)\n",
    "    input_image_shape = (50, 50, 1)\n",
    "\n",
    "    # input_layer = Input(shape=input_image_dim) # To feed the image into the network they must have matching dimensions\n",
    "\n",
    "    # generated_images = generator(input_layer) # the output for the generator network will be\n",
    "\n",
    "\n",
    "    img_height, img_width = input_image_shape[:2]\n",
    "    patch_height, patch_width = patch_shape\n",
    "\n",
    "    # for every picture we are going to  take it pixel by pixel for this one to train, one can choose to have\n",
    "    # bigger patches if needed or maller\n",
    "    row_index = [(i * patch_height, (i + 1) * patch_height) for i in range(int(img_height / patch_height))]\n",
    "    column_index = [(i * patch_width, (i + 1) * patch_width) for i in range(int(img_width / patch_width))]\n",
    "\n",
    "\n",
    "    patches = []\n",
    "    for row_idx in row_index:\n",
    "        for column_idx in column_index:\n",
    "            continue\n",
    "    #             patches.append(Lambda(lambda z: z[:, column_index[0]:column_index[1], row_index[0]:row_index[1], :],\n",
    "    #     output_shape=input_image_shape)(generated_images))\n",
    "\n",
    "\n",
    "    # We definetely don't want out discriminator training at the same time were testing things \n",
    "    discriminator.trainable = False\n",
    "\n",
    "    discriminator_output = discriminator(patches)\n",
    "\n",
    "    pix2pix_model = Model(inputs=[input_layer], outputs=[generated_images,  \n",
    "                  discriminator_output])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pix2pix_network():\n",
    "    \n",
    "    # Hyperparameters\n",
    "    training_epochs = 500 # this is gonna have to be variable\n",
    "    images_per_epoch = 10 # For this smaller dataset\n",
    "    batch_size = 1\n",
    "    image_width = 50\n",
    "    image_height = 50\n",
    "    num_channels = 1 # if not Black and white this should be turned to 3 for RBG\n",
    "    input_image_shape = (50, 50, 1)\n",
    "    patch_shape = (50, 50)\n",
    "    dataset_dir = './'\n",
    "    shared_optimizer = Adam(lr=1E-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08) # The optimizer that all of the functions will use\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
